# Paper-Record

### ì½ì€ ë…¼ë¬¸ì„ ì •ë¦¬í•˜ê³ , ì½ì„ ë…¼ë¬¸ì„ ê¸°ë¡í•´ë‘ëŠ” Repoì…ë‹ˆë‹¤. ğŸ“–

ì½ì€ ë…¼ë¬¸ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [Issues](https://github.com/Songinpyo/Paper-Record/issues)ì— ë³„ë„ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.

### ê° Issue ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
â“ Why â†’ í•´ë‹¹ ë…¼ë¬¸ì˜ í•„ìš”ì„±, abstract

ğŸ’¡ Key insights â†’ í•´ë‹¹ ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´

ğŸ”— Reference URL â†’ ë…¼ë¬¸ ë§í¬

# Paper I read ğŸ“

### â—‹ 2D Human Pose Estimation
|ì œëª©|í•µì‹¬ ë‚´ìš©|
|------|---|
|[Deep High-Resolution Representation Learning for Human Pose Estimation](https://github.com/Songinpyo/Paper-Record/issues/2) [CVPR2019]|ì „ì²´ Networkì— ê±¸ì³ High-Resolutionì„ ìœ ì§€í•˜ê³  ë³‘ë ¬ì  fuseë¥¼ í†µí•´ ë‹¤ë¥¸ Resolution ì‚¬ì´ ì •ë³´ êµí™˜ì´ ì´ë£¨ì–´ì§„ë‹¤.|
|Deep High-Resolution Representation Learning for Visual Recognition [CVPR2020]|2019 HRNetê³¼ ì•„ì´ë””ì–´ëŠ” ê°™ì§€ë§Œ, High-Resolutionìœ¼ë¡œë¶€í„°ë§Œ representaitonì„ êµ¬í•˜ë˜ HRNetV1ê³¼ ë‹¬ë¦¬ 4ê°œì˜ Resolution ëª¨ë‘ì— ì§‘ì¤‘í•˜ëŠ” HRNetV2, HRNetV2p ì€ ê°ê° Semantic segmentation, Object detectionì— ì‚¬ìš©ëœë‹¤.|
|Multi-Instance Pose Networks: Rethinking Top-Down Pose Estimation [ICCV2021]|ê¸°ì¡´ì˜ Top-down method architectureì— Multi Instance Modulation Blockì„ ì ìš©í•˜ì—¬ Bounding boxë‚´ì˜ multi instance ì¸ì‹ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤. íŒŒë¼ë¯¸í„° ì¦ê°€ 3% ìˆ˜ì¤€ìœ¼ë¡œ ë§¤ìš° íš¨ìœ¨ì |
|[Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation](https://github.com/Songinpyo/Paper-Record/issues/1) [CVPR2021]|Bottom-up methodì—ì„œ Human scale varianceì™€ labeling ambiguitiesë¥¼ ê³ ë ¤í•˜ì§€ ì•ŠëŠ” fixed Standard deviationsë¥¼ ì“°ëŠ” ê²ƒì€ ë¬¸ì œê°€ ìˆë‹¤. ì´ë¥¼ ìœ„í•´ Scale-adaptive heatmap regressionê³¼ Weight-adaptive heatmap regressionì„ ì œì•ˆí•œë‹¤.|
|[Deep Dual Consecutive Network for Human Pose Estimation](https://github.com/Songinpyo/Paper-Record/issues/3) [CVPR2021]|ì—°ì†ì ì¸ ì´ë¯¸ì§€ ì¦‰, Videoì—ì„œ Human Pose Estimationì€ motion blur, video defocus, occlusions ë“± ë‹¤ì–‘í•œ ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. í•´ë‹¹ ë…¼ë¬¸ì€ Key Point detectionì„ ìœ„í•´ ê³¼ê±°ì™€ ë¯¸ë˜ì˜ ë¹„ë””ì˜¤ í”„ë ˆì„ì˜ temporal cuesë¥¼ í™œìš©í•˜ëŠ” multi-frame HPEë¥¼ ì œì•ˆí•œë‹¤.|
|[OTPose: Occlusion-Aware Transformer for Pose Estimation in Sparsely-Labeled Videos](https://github.com/Songinpyo/Paper-Record/issues/16)[2022]|ì œí•œì ì¸ receptive fieldë¥¼ ê°€ì§€ëŠ” CNNì˜ ê·¼ë³¸ì  í•œê³„ì™€ main challengeì¸ occlusionì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ í”„ë ˆì„ì˜ ì¡°í•©ê³¼ transformerë¥¼ ì´ìš©í•´ì„œ Occlusion aware heatmap, Occlusion Attension maskë¥¼ ìƒì„±í•œë‹¤. Posetrack SOTA |

### â—‹ 3D Human Mesh Reconstruction
|ì œëª©|í•µì‹¬ ë‚´ìš©|
|------|---|
|[Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image](https://github.com/Songinpyo/Paper-Record/issues/10) [ECCV2016]|2D monocular imageë¡œë¶€í„° 3D meshë¥¼ ì¶”ì •í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•œ ë…¼ë¬¸, í˜„ì¬ê¹Œì§€ë„ smpl parameterë¥¼ ì¶”ì •í•˜ëŠ” ë°©ë²• ì‚¬ìš©í•˜ëŠ” ë…¼ë¬¸ë“¤ì— ê¾¸ì¤€íˆ ì‚¬ìš©ë˜ê³  ìˆë‹¤.|
|[The Power of Points for Modeling Humans in Clothing](https://github.com/Songinpyo/Paper-Record/issues/11) [ICCV2021]|ê¸°ì¡´ì˜ meshê¸°ë°˜, implicit surface ê¸°ë°˜ 3D reconstructionì—ì„œ pose base cloth deformationê°™ì€ Detailí•œ ë¶€ë¶„ì„ ì˜ ë‚˜íƒ€ë‚´ì§€ ëª»í•œ ê²ƒì„ point cloud ê¸°ë°˜ ë°©ë²•ìœ¼ë¡œ realistically êµ¬í˜„í•˜ì˜€ë‹¤.|
|[3D Clothed Human Reconstruction in the Wild](https://github.com/Songinpyo/Paper-Record/issues/12) [ECCV2022]|ê¸°ì¡´ì˜ dataë¡œ ì‚¬ìš©ë˜ë˜ ë°ì´í„°ëŠ” ì œì•½ì¡°ê±´í•˜ì— ì´¬ì˜ëœ 3D rendered imagesë¥¼ ì‚¬ìš©í•˜ì˜€ê¸° ë•Œë¬¸ì— in-the-wild imagesë¥¼ ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ í° domain gapì´ ì¡´ì¬í•œë‹¤. ì´ì²˜ëŸ¼ 3D ëŒ€ì‹  2Dë¥¼ targetìœ¼ë¡œ í•˜ëŠ” weakly supervisingì—ì„œ ë°œìƒí•˜ëŠ” depth ambiguity ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ì„œ DensePose based lossë¥¼ ë„ì…í•œë‹¤. í•´ë‹¹ modelì€ SMPLê³¼ SMPLicitì„ ê¸°ë°˜ìœ¼ë¡œ clothed human meshë¥¼ ë³µì›í•œë‹¤.|
|[HMR : End-to-end Recovery of Human Shape and Pose](https://github.com/Songinpyo/Paper-Record/issues/17) [CVPR 2018]|3D annotationì´ ì—†ëŠ” In-the-wild imageë¥¼ direct ë°©ì‹ìœ¼ë¡œ 3D mesh reconstructionì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•˜ì˜€ë‹¤. GANì˜ adversarial training methodë¥¼ ì°¨ìš©í•˜ì—¬ discriminatorë¥¼ í†µí•´ ì‚¬ì‹¤ì ì¸ reconstructionì´ ê°€ëŠ¥í•˜ê²Œ í•˜ì˜€ë‹¤.|
|[SPIN : Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop](https://github.com/Songinpyo/Paper-Record/issues/18) [ICCV 2019]|Optimizationê³¼ Regressionì„ ìƒí˜¸ë³´ì™„ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ Regressionì€ Optimizationì—ê²Œ ì¢‹ì€ initializationì„ ì œê³µí•˜ê³ , ê·¸ë ‡ê²Œ ì–»ì–´ì§„ Optimizationì€ Regressionì˜ ì¢‹ì€ Supervisionì´ ë  ìˆ˜ ìˆë‹¤. ìŠ¤ìŠ¤ë¡œ Supervisionì„ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— ë³„ë„ì˜ 3D annoationì—†ì´ 2D annotationë§Œ ìˆëŠ” In-the-wild imageì—ì„œë„ ì‚¬ìš©ê°€ëŠ¥í•˜ë‹¤.|
|[VIBE: Video Inference for Human Body Pose and Shape Estimation](https://github.com/Songinpyo/Paper-Record/issues/19) [CVPR 2020]|ë¹„ë””ì˜¤ì—ì„œ temporal informationì„ ì´ìš©í•´ ì •í™•í•˜ê²Œ 3D Motion ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•œ ë…¼ë¬¸ìœ¼ë¡œì„œ RNN architectureì˜ ì‚¬ìš©ìœ¼ë¡œ informationì„ over time propagate í•˜ì˜€ë‹¤. AMASS datasetì„ ì´ìš©í•˜ì—¬ motion sequenceë¥¼ í•™ìŠµì‹œí‚¨ discriminatorë¥¼ ì œì•ˆí•œë‹¤. Discriminatorì— self-attentionì„ ì ìš©í•˜ì—¬ human motionì— ì¤‘ìš”í•œ temporal structureì— ì§‘ì¤‘í•˜ë„ë¡ í•œë‹¤.|

### â—‹ Vision
|ì œëª©|í•µì‹¬ ë‚´ìš©|
|------|---|
|[Deep Residual Learning for Image Recognition](https://github.com/Songinpyo/Paper-Record/issues/4) [IEEE2016]|Residual learningì„ í†µí•´ deeper networkë¥¼ ì‰½ê²Œ ìµœì í™” ì‹œí‚¤ê³ , deeper layerê°€ ìœ ë°œí•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤. Residual block, Bottleneck block|
|[Feature Pyramid Networks for Object Detection](https://github.com/Songinpyo/Paper-Record/issues/5) [CVPR2017]|Deep Convolution Networkì— Feature pyraimd êµ¬ì¡°ë¥¼ ì‚¬ìš©í•œë‹¤. Low resolution High featureë¥¼ up-conví•˜ì—¬ í•˜ìœ„ layerì˜ featureë“¤ê³¼ ë”í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ featureë¥¼ ì¶”ì¶œí•´ë‚¸ë‹¤.|
|[Learning Transferable Visual Models From Natural Language Supervision](https://github.com/Songinpyo/Paper-Record/issues/13) [OpenAI2021]|Textì™€ Imageë¥¼ ë™ì‹œì— í•™ìŠµì‹œí‚¤ëŠ” ë°©ì‹ì„ í†µí•´ì„œ Classification taskì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. Trainingì—ëŠ” ëŒ€ëŸ‰ì˜ raw data InferenceëŠ” Zero-shotìœ¼ë¡œ ì§„í–‰ë˜ëŠ” íŠ¹ì§•ì´ ìˆë‹¤.|

### â—‹ Temporal
|ì œëª©|í•µì‹¬ ë‚´ìš©|
|------|---|
|[TF-Blender: Temporal Feature Blender for Video Object Detection](https://github.com/Songinpyo/Paper-Record/issues/9) [ICCV2021]|Multi frame ì‚¬ìš©ì‹œ ëª¨ë“  í”„ë ˆì„ì´ ìƒí˜¸ê°„ ì˜í–¥ì„ ì£¼ê³  ë°›ìŒìœ¼ë¡œì¨ feature dgrading ë¬¸ì œë¥¼ í•´ê²°í•˜ì˜€ë‹¤. í˜„ì¬ í”„ë ˆì„ê³¼ ì£¼ë³€ í”„ë ˆì„ê°„ì˜ ê´€ê³„ë¥¼ ì´ìš©í•œ adaptive weight, í˜„ì¬ í”„ë ˆì„ì„ ì œì™¸í•œ ì£¼ë³€ í”„ë ˆì„ê°„ì˜ ê´€ê³„ë¥¼ ì´ìš©í•œ featrue adjustmentì˜ ì‚¬ìš©ìœ¼ë¡œ ì–´ëŠ ëª¨ë¸ì—ë‚˜ ì ìš©ê°€ëŠ¥í•œ irreleventí•œ featureë¥¼ ìƒì„±í•œë‹¤.|
|[FlowNet: Learning Optical Flow with Convolutional Networks](https://github.com/Songinpyo/Paper-Record/issues/8) [IEEE2015]|Optical flowì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª…ê³¼, Optical flowë¥¼ êµ¬í•˜ëŠ”ë° CNNì„ ì‚¬ìš©í•œ ëª¨ë¸ì„ ì œì‹œí•œë‹¤.|

### â—‹ Transformer
|ì œëª©|í•µì‹¬ ë‚´ìš©|
|------|---|
|[AN IMAGE IS WORTH 16X16 WORDS:TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE](https://github.com/Songinpyo/Paper-Record/issues/6) [ICLR2021]|CNNì„ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•Šê³  Transformerë§Œì„ ì´ìš©í•œ Image classifierë¥¼ ë§Œë“ ë‹¤. ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ë¡œ ë‚˜ëˆ„ê³  linear projectionìœ¼ë¡œ íŒ¨ì¹˜ì˜ ì°¨ì›ì„ ë³€í™˜í•˜ì—¬ íŒ¨ì¹˜ ì„ë² ë”©ì„ êµ¬ì¶•í•œë‹¤. íŒ¨ì¹˜ ì„ë² ë”©ê³¼ ìœ„ì¹˜ ì„ë² ë”©ì„ Transformer Encoderì— ë„£ì–´ feature representationì„ ì¶”ì¶œí•˜ê³  ì´ë¥¼ MLP headì— ë„£ì–´ ìµœì¢…ì ìœ¼ë¡œ classë¥¼ ë¶„ë¥˜í•œë‹¤.|
|[Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://github.com/Songinpyo/Paper-Record/issues/14) [ICCV2021]|Local Windowë¥¼ ì ìš©í•˜ì—¬ inductive bias ì¦ê°€, Patch Mergingì„ í†µí•´ Hierarchical êµ¬ì¡° í˜•ì„± ë³´ë‹¤ ì‘ì€ ë¬¼ì²´ë„ ì¸ì§€ ê°€ëŠ¥, ì´ë¯¸ì§€ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ Transformer êµ¬ì¡°|
|[Vision Transformer with Deformable Attention](https://github.com/Songinpyo/Paper-Record/issues/15) [CVPR2022]|Deformable Attention Moduleì„ ì´ìš©í•˜ì—¬ íŠ¹ì • queryì— ëŒ€í•´ attentionì„ ì§‘ì¤‘ì‹œí‚¬ ìˆ˜ ìˆìœ¼ë©°, Swinì—ì„œ ì‚¬ìš©ëœ W-MSA, SW-MSA ë¥¼ ì´ìš©í•˜ì—¬ ì—°ì‚°ëŸ‰ì„ ì¤„ì˜€ë‹¤. Object detection, Segmentationì— ë³´ë‹¤ ì í•©í•œ Backboneìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤.|

# Paper I'll read âœï¸

### â—‹ Human Pose Estimation
|ì œëª©|ê¸°í•œ|
|------|---|

### â—‹ Vision
|ì œëª©|ê¸°í•œ|
|------|---|
|Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results [Alibaba]|22.06.25|
|DeiT: Training Data-Efficient Image Transformer & Distillation through Attention|22.06.30|
