# Paper-Record

### ì½ì€ ë…¼ë¬¸ì„ ì •ë¦¬í•˜ê³ , ì½ì„ ë…¼ë¬¸ì„ ê¸°ë¡í•´ë‘ëŠ” Repoì…ë‹ˆë‹¤. ğŸ“–

ì½ì€ ë…¼ë¬¸ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [Issues](https://github.com/Songinpyo/Paper-Record/issues)ì— ë³„ë„ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.

### ê° Issue ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
â“ Why â†’ í•´ë‹¹ ë…¼ë¬¸ì˜ í•„ìš”ì„±, abstract

ğŸ’¡ Key insights â†’ í•´ë‹¹ ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´

ğŸ”— Reference URL â†’ ë…¼ë¬¸ ë§í¬

# Paper I read ğŸ“

### â—‹ 2D Human Pose Estimation
|ì œëª©|í•µì‹¬ ë‚´ìš©|
|------|---|
|[Deep High-Resolution Representation Learning for Human Pose Estimation](https://github.com/Songinpyo/Paper-Record/issues/2) [CVPR2019]|ì „ì²´ Networkì— ê±¸ì³ High-Resolutionì„ ìœ ì§€í•˜ê³  ë³‘ë ¬ì  fuseë¥¼ í†µí•´ ë‹¤ë¥¸ Resolution ì‚¬ì´ ì •ë³´ êµí™˜ì´ ì´ë£¨ì–´ì§„ë‹¤.|
|Deep High-Resolution Representation Learning for Visual Recognition [CVPR2020]|2019 HRNetê³¼ ì•„ì´ë””ì–´ëŠ” ê°™ì§€ë§Œ, High-Resolutionìœ¼ë¡œë¶€í„°ë§Œ representaitonì„ êµ¬í•˜ë˜ HRNetV1ê³¼ ë‹¬ë¦¬ 4ê°œì˜ Resolution ëª¨ë‘ì— ì§‘ì¤‘í•˜ëŠ” HRNetV2, HRNetV2p ì€ ê°ê° Semantic segmentation, Object detectionì— ì‚¬ìš©ëœë‹¤.|
|Multi-Instance Pose Networks: Rethinking Top-Down Pose Estimation [ICCV2021]|ê¸°ì¡´ì˜ Top-down method architectureì— Multi Instance Modulation Blockì„ ì ìš©í•˜ì—¬ Bounding boxë‚´ì˜ multi instance ì¸ì‹ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤. íŒŒë¼ë¯¸í„° ì¦ê°€ 3% ìˆ˜ì¤€ìœ¼ë¡œ ë§¤ìš° íš¨ìœ¨ì |
|[Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation](https://github.com/Songinpyo/Paper-Record/issues/1) [CVPR2021]|Bottom-up methodì—ì„œ Human scale varianceì™€ labeling ambiguitiesë¥¼ ê³ ë ¤í•˜ì§€ ì•ŠëŠ” fixed Standard deviationsë¥¼ ì“°ëŠ” ê²ƒì€ ë¬¸ì œê°€ ìˆë‹¤. ì´ë¥¼ ìœ„í•´ Scale-adaptive heatmap regressionê³¼ Weight-adaptive heatmap regressionì„ ì œì•ˆí•œë‹¤.|
|[Deep Dual Consecutive Network for Human Pose Estimation](https://github.com/Songinpyo/Paper-Record/issues/3) [CVPR2021]|ì—°ì†ì ì¸ ì´ë¯¸ì§€ ì¦‰, Videoì—ì„œ Human Pose Estimationì€ motion blur, video defocus, occlusions ë“± ë‹¤ì–‘í•œ ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤. í•´ë‹¹ ë…¼ë¬¸ì€ Key Point detectionì„ ìœ„í•´ ê³¼ê±°ì™€ ë¯¸ë˜ì˜ ë¹„ë””ì˜¤ í”„ë ˆì„ì˜ temporal cuesë¥¼ í™œìš©í•˜ëŠ” multi-frame HPEë¥¼ ì œì•ˆí•œë‹¤.|

### â—‹ 3D Human Mesh Reconstruction
|ì œëª©|í•µì‹¬ ë‚´ìš©|
|------|---|
|[Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image](https://github.com/Songinpyo/Paper-Record/issues/10) [ECCV2016]|2D monocular imageë¡œë¶€í„° 3D meshë¥¼ ì¶”ì •í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•œ ë…¼ë¬¸, í˜„ì¬ê¹Œì§€ë„ smpl parameterë¥¼ ì¶”ì •í•˜ëŠ” ë°©ë²• ì‚¬ìš©í•˜ëŠ” ë…¼ë¬¸ë“¤ì— ê¾¸ì¤€íˆ ì‚¬ìš©ë˜ê³  ìˆë‹¤.|
|[The Power of Points for Modeling Humans in Clothing](https://github.com/Songinpyo/Paper-Record/issues/11) [ICCV2021]|ê¸°ì¡´ì˜ meshê¸°ë°˜, implicit surface ê¸°ë°˜ 3D reconstructionì—ì„œ pose base cloth deformationê°™ì€ Detailí•œ ë¶€ë¶„ì„ ì˜ ë‚˜íƒ€ë‚´ì§€ ëª»í•œ ê²ƒì„ point cloud ê¸°ë°˜ ë°©ë²•ìœ¼ë¡œ realistically êµ¬í˜„í•˜ì˜€ë‹¤.|
|[3D Clothed Human Reconstruction in the Wild](https://github.com/Songinpyo/Paper-Record/issues/12) [ECCV2022]|ê¸°ì¡´ì˜ dataë¡œ ì‚¬ìš©ë˜ë˜ ë°ì´í„°ëŠ” ì œì•½ì¡°ê±´í•˜ì— ì´¬ì˜ëœ 3D rendered imagesë¥¼ ì‚¬ìš©í•˜ì˜€ê¸° ë•Œë¬¸ì— in-the-wild imagesë¥¼ ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ í° domain gapì´ ì¡´ì¬í•œë‹¤. ì´ì²˜ëŸ¼ 3D ëŒ€ì‹  2Dë¥¼ targetìœ¼ë¡œ í•˜ëŠ” weakly supervisingì—ì„œ ë°œìƒí•˜ëŠ” depth ambiguity ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ì„œ DensePose based lossë¥¼ ë„ì…í•œë‹¤. í•´ë‹¹ modelì€ SMPLê³¼ SMPLicitì„ ê¸°ë°˜ìœ¼ë¡œ clothed human meshë¥¼ ë³µì›í•œë‹¤.|

### â—‹ Vision
|ì œëª©|í•µì‹¬ ë‚´ìš©|
|------|---|
|[Deep Residual Learning for Image Recognition](https://github.com/Songinpyo/Paper-Record/issues/4) [IEEE2016]|Residual learningì„ í†µí•´ deeper networkë¥¼ ì‰½ê²Œ ìµœì í™” ì‹œí‚¤ê³ , deeper layerê°€ ìœ ë°œí•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤. Residual block, Bottleneck block|
|[Feature Pyramid Networks for Object Detection](https://github.com/Songinpyo/Paper-Record/issues/5) [CVPR2017]|Deep Convolution Networkì— Feature pyraimd êµ¬ì¡°ë¥¼ ì‚¬ìš©í•œë‹¤. Low resolution High featureë¥¼ up-conví•˜ì—¬ í•˜ìœ„ layerì˜ featureë“¤ê³¼ ë”í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ featureë¥¼ ì¶”ì¶œí•´ë‚¸ë‹¤.|

### â—‹ Temporal
|ì œëª©|í•µì‹¬ ë‚´ìš©|
|------|---|
|[TF-Blender: Temporal Feature Blender for Video Object Detection](https://github.com/Songinpyo/Paper-Record/issues/9) [ICCV2021]|Multi frame ì‚¬ìš©ì‹œ ëª¨ë“  í”„ë ˆì„ì´ ìƒí˜¸ê°„ ì˜í–¥ì„ ì£¼ê³  ë°›ìŒìœ¼ë¡œì¨ feature dgrading ë¬¸ì œë¥¼ í•´ê²°í•˜ì˜€ë‹¤. í˜„ì¬ í”„ë ˆì„ê³¼ ì£¼ë³€ í”„ë ˆì„ê°„ì˜ ê´€ê³„ë¥¼ ì´ìš©í•œ adaptive weight, í˜„ì¬ í”„ë ˆì„ì„ ì œì™¸í•œ ì£¼ë³€ í”„ë ˆì„ê°„ì˜ ê´€ê³„ë¥¼ ì´ìš©í•œ featrue adjustmentì˜ ì‚¬ìš©ìœ¼ë¡œ ì–´ëŠ ëª¨ë¸ì—ë‚˜ ì ìš©ê°€ëŠ¥í•œ irreleventí•œ featureë¥¼ ìƒì„±í•œë‹¤.|
|[FlowNet: Learning Optical Flow with Convolutional Networks](https://github.com/Songinpyo/Paper-Record/issues/8) [IEEE2015]|Optical flowì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª…ê³¼, Optical flowë¥¼ êµ¬í•˜ëŠ”ë° CNNì„ ì‚¬ìš©í•œ ëª¨ë¸ì„ ì œì‹œí•œë‹¤.|

### â—‹ Transformer
|ì œëª©|í•µì‹¬ ë‚´ìš©|
|------|---|
|[AN IMAGE IS WORTH 16X16 WORDS:TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE](https://github.com/Songinpyo/Paper-Record/issues/6) [ICLR2021]|CNNì„ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•Šê³  Transformerë§Œì„ ì´ìš©í•œ Image classifierë¥¼ ë§Œë“ ë‹¤. ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ë¡œ ë‚˜ëˆ„ê³  linear projectionìœ¼ë¡œ íŒ¨ì¹˜ì˜ ì°¨ì›ì„ ë³€í™˜í•˜ì—¬ íŒ¨ì¹˜ ì„ë² ë”©ì„ êµ¬ì¶•í•œë‹¤. íŒ¨ì¹˜ ì„ë² ë”©ê³¼ ìœ„ì¹˜ ì„ë² ë”©ì„ Transformer Encoderì— ë„£ì–´ feature representationì„ ì¶”ì¶œí•˜ê³  ì´ë¥¼ MLP headì— ë„£ì–´ ìµœì¢…ì ìœ¼ë¡œ classë¥¼ ë¶„ë¥˜í•œë‹¤.|

# Paper I'll read âœï¸

### â—‹ Human Pose Estimation
|ì œëª©|ê¸°í•œ|
|------|---|

### â—‹ Vision
|ì œëª©|ê¸°í•œ|
|------|---|
|Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results [Alibaba]|22.06.25|
|DeiT: Training Data-Efficient Image Transformer & Distillation through Attention|22.06.30|
